{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user GitPython\n",
    "# pip install --user rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleColab = False\n",
    "\n",
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if GoogleColab:\n",
    "  ## mount connection to personal drive\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "  ## root directory:\n",
    "  root = \"/content/drive/MyDrive/\"\n",
    "\n",
    "  !pip install gitpython\n",
    "  import git\n",
    "\n",
    "  root = \"/content/drive/MyDrive/dmPC/scripts_model\"\n",
    "\n",
    "else: \n",
    "  # Verify we're in the correct working directory\n",
    "\n",
    "  import git \n",
    "\n",
    "  def get_project_root():\n",
    "      return Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "  root = get_project_root()\n",
    "\n",
    "\n",
    "os.chdir(root)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GoogleColab:\n",
    "  plot_folder = \"../images/GDSC/\"\n",
    "else:\n",
    "  plot_folder = \"images/GDSC/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages, models, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if GoogleColab:\n",
    "  !pip install modin\n",
    "  # pip install -U ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('pytorch version:', torch.__version__)\n",
    "print('orig num threads:', torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from trainers import *\n",
    "from losses import *\n",
    "from utils import *\n",
    "# from cpd_smiles_embed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/GDSC\"\n",
    "c_data = pd.read_csv(os.path.join(data_folder, \"c_data.csv\"), index_col = 0)\n",
    "c_meta = pd.read_csv(os.path.join(data_folder, \"c_meta.csv\"), index_col = 0)\n",
    "# RNAseq_meta['COSMIC_ID'] = RNAseq_meta['COSMIC_ID'].astype(int)\n",
    "\n",
    "d_data = pd.read_csv(os.path.join(data_folder, \"d_data.csv\"), index_col = 0)\n",
    "\n",
    "cdr = pd.read_csv(os.path.join(data_folder, \"cdr.csv\"), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Skin cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_types = [\"ALL\",\"LAML\", \"LCML\", \"CLL\", \"DLBC\", \"SKCM\"]\n",
    "c_type_str = 'skin_ll'\n",
    "\n",
    "c_meta = c_meta[c_meta[\"cancer_type\"].isin(c_types)]\n",
    "c_data = c_data[c_data.index.isin(c_meta[\"COSMIC_ID\"])]\n",
    "cdr = cdr[cdr.index.isin(c_meta[\"COSMIC_ID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare c_meta, \n",
    "c_meta_id_col_name = 'COSMIC_ID'\n",
    "c_meta_type_col_name = 'cancer_type'\n",
    "\n",
    "c_meta = c_meta[[c_meta_id_col_name, c_meta_type_col_name]]\n",
    "c_meta = c_meta.rename(columns = {c_meta_id_col_name:'C_ID', c_meta_type_col_name:'C_type'})\n",
    "c_meta = c_meta[~c_meta['C_ID'].isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test stability\n",
    "test_stability = False\n",
    "if test_stability:\n",
    "    # Randomly sample 20% of the DataFrame\n",
    "    sampled_rows = c_meta.sample(frac=0.15)\n",
    "\n",
    "    # Set the value of 'C_type' in these rows to 'Other'\n",
    "    c_meta.loc[sampled_rows.index, 'C_type'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_init_cluster = True\n",
    "cluster_method = \"seld_define\" # \"KMeans\"\n",
    "if new_init_cluster:\n",
    "    if cluster_method == \"seld_define\":\n",
    "        c_meta.loc[c_meta['C_type'].isin([\"ALL\",\"LAML\", \"LCML\", \"CLL\"]), 'C_type'] = 'leukemia'\n",
    "        c_meta.loc[c_meta['C_type'].isin([\"DLBC\"]), 'C_type'] = 'lymphoma'\n",
    "\n",
    "    if cluster_method == \"KMeans\":\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.cluster import kmeans_plusplus\n",
    "        from sklearn.cluster import KMeans\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        cdr_tmp = cdr.fillna(-1).to_numpy()\n",
    "        # cdr_tmp.dtypes\n",
    "        centers_init, indices = kmeans_plusplus(cdr_tmp, n_clusters=2, random_state=0)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=2, init=centers_init, n_init=1, random_state=0)\n",
    "        kmeans.fit(cdr_tmp)\n",
    "\n",
    "        cluster_assignments = kmeans.labels_ \n",
    "\n",
    "        combined = np.column_stack((cluster_assignments, cdr_tmp))\n",
    "\n",
    "        # Sort by cluster assignments\n",
    "        combined_sorted = combined[combined[:, 0].argsort()]\n",
    "\n",
    "        # Removing the cluster assignment column for the heatmap\n",
    "        data_sorted = combined_sorted[:, 1:]\n",
    "\n",
    "        # Create the heatmap\n",
    "        plt.figure(figsize=(10, 10))  # You can adjust the size as needed\n",
    "        sns.heatmap(data_sorted, cmap='viridis')  # Choose a colormap that fits your preferences\n",
    "        plt.title('Heatmap of CDR Sorted by Cluster Assignments')\n",
    "        plt.show()\n",
    "\n",
    "        c_meta.loc['C_type'] = cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta, meta_map = get_CCL_meta_codes(c_data.index.values, c_meta)\n",
    "c_meta.index = c_meta.index.astype(str)\n",
    "\n",
    "print(f\"Cancer type coding map: \")\n",
    "print(meta_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_counts = c_meta['code'].value_counts()\n",
    "print(column_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. prepare c_data\n",
    "## make sure: \n",
    "##   1. the index (row names) is cancer cell line names\n",
    "c_data.index = c_data.index.astype(str)\n",
    "c_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. prepare d_data\n",
    "## make sure: \n",
    "##   1. the index (row names) is drug names\n",
    "# cpd_smiles = cpd_smiles[['drug_id', 'smiles']]\n",
    "# cpd_smiles = cpd_smiles.set_index('drug_id')\n",
    "\n",
    "# d_data = smiles_to_AtonBondDescriptor_PCAembedings(cpd_smiles)\n",
    "d_data.index = d_data.index.astype(str)\n",
    "\n",
    "d_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. prepare cdr\n",
    "## make sure: \n",
    "##   1. the index (row names) is cancer cell line names\n",
    "##   2. the columns (column names) is drug names\n",
    "cdr.index = cdr.index.astype(\"str\")\n",
    "\n",
    "common_drugs = list(set(cdr.columns).intersection(set(d_data.index)))\n",
    "cdr = cdr[common_drugs]\n",
    "d_data = d_data.loc[common_drugs]\n",
    "\n",
    "common_cancers = list(set(cdr.index).intersection(set(c_data.index)))\n",
    "cdr = cdr.loc[common_cancers]\n",
    "c_data = c_data.loc[common_cancers]\n",
    "c_meta = c_meta.loc[common_cancers]\n",
    "\n",
    "print(f'cdr shape: {cdr.shape}')\n",
    "print(f'c_data shape: {c_data.shape}')\n",
    "print(f'c_meta shape: {c_meta.shape}')\n",
    "print(f'd_data shape: {d_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    valid_size = 0.2 #@param {type: \"float\"}\n",
    "\n",
    "    n_epochs = 80 #@param {type: \"integer\"} # 100\n",
    "    batch_size = 80 #@param {type: \"integer\"} # 50\n",
    "    lr = 0.01 #@param {type: \"float\"}\n",
    "\n",
    "    num_workers = 1\n",
    "    \n",
    "    C_VAE_loss_weight = 0.5 #@param {type: \"float\"}\n",
    "    C_recon_loss_weight = 0.1 #@param {type: \"float\"}\n",
    "    C_kld_weight = 0.5 #@param {type: \"float\"} # 0.5\n",
    "    C_cluster_distance_weight = 220 #@param {type: \"float\"}\n",
    "    C_update_ratio_weight = 10 #@param {type: \"float\"}\"}\n",
    "    \n",
    "    D_VAE_loss_weight = 1 #@param {type: \"float\"}\n",
    "    D_recon_loss_weight = 1 #@param {type: \"float\"}\n",
    "    D_kld_weight = 0.5 #@param {type: \"float\"}\n",
    "    D_cluster_distance_weight = 200 #@param {type: \"float\"}\n",
    "    D_update_ratio_weight = 10 #@param {type: \"float\"}\n",
    "    \n",
    "    predict_loss_weight = 4000 #@param {type: \"float\"}\n",
    "    \n",
    "    cVAE_save_path = 'data/model_fits/GDSC_' + c_type_str + '_c_vae' #@param\n",
    "    dVAE_save_path = 'data/model_fits/GDSC_' + c_type_str + '_d_vae' #@param\n",
    "    \n",
    "    c_p_save_path = 'data/model_fits/GDSC_' + c_type_str + '_c_vae_predictor' #@param\n",
    "    d_p_save_path = 'data/model_fits/GDSC_' + c_type_str + '_d_vae_predictor' #@param\n",
    "\n",
    "    use_weighted_bce = True\n",
    "    use_mixture_kld = False\n",
    "\n",
    "\n",
    "\n",
    "class CDPModel_sub_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    # c_VAE\n",
    "    c_input_dim = 0 #@param {type: \"integer\"}\n",
    "    c_h_dims = [1024, 512, 256, 128] #@param {type: \"vactor\"}\n",
    "    c_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # d_VAE\n",
    "    d_input_dim = 0 #@param {type: \"integer\"}\n",
    "    d_h_dims = [64]  #@param {type: \"vactor\"}\n",
    "    d_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # predictor\n",
    "    p_sec_dim = 16 #@param {type: \"integer\"}\n",
    "    p_h_dims = [p_sec_dim*2, 16]  #@param {type: \"vactor\"}\n",
    "    \n",
    "    # all\n",
    "    drop_out = 0  #@param {type: \"float\"}\n",
    "    \n",
    "    # sensitive threshold\n",
    "    sens_cutoff = 0.5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Train_Args()\n",
    "\n",
    "K = len(c_meta[c_meta['code'] != -1]['code'].unique())\n",
    "\n",
    "CDPmodel_args = CDPModel_sub_Args()\n",
    "CDPmodel_args['c_input_dim'] = c_data.shape[1] \n",
    "CDPmodel_args['d_input_dim'] = d_data.shape[1]\n",
    "\n",
    "if CDPmodel_args['c_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nCancer Cell line feature number not specified''')\n",
    "if CDPmodel_args['d_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nDrug feature number not specified''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDPmodel = CDPmodel(K, CDPmodel_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Best epoc with test loss: epoch 20\n",
      "            Running time: 3735.4372770786285\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a321cad2c048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCDPmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_subcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dmPC_old/scripts_model/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, c_data, c_meta, d_data, cdr, train_params, n_rounds, search_subcluster, device, seed)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mzero_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_centroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_centroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_sd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_sd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_name_cluster_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_name_sensitive_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_train_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     best_epos, c_meta_k, d_sens_k = train_CDPmodel_local_1round(self.CDPmodel_list[k], device, False, c_data, c_meta_k, d_data, \\\n\u001b[0m\u001b[1;32m    284\u001b[0m                                                                                 cdr, c_names_k_init, d_names_k_init, sensitive_cut_off, k, train_params)\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dmPC_old/scripts_model/trainers.py\u001b[0m in \u001b[0;36mtrain_CDPmodel_local_1round\u001b[0;34m(model, device, ifsubmodel, c_data, c_meta_k, d_data, cdr_org, c_names_k_init, d_names_k_init, sens_cutoff, k, params)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# get predicted CDR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mc_latentTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_VAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcdr_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0md_latentTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_VAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcdr_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0my_hatTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_latentTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_latentTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m         return self.obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   1274\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5430\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5431\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   5432\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5433\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    745\u001b[0m             )\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m    748\u001b[0m                 blk.take_nd(\n\u001b[1;32m    749\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             new_blocks = [\n\u001b[0;32m--> 748\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m    749\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "n_rounds = 4\n",
    "fit_returns = CDPmodel.fit(c_data, c_meta, d_data, cdr, train_args, n_rounds=n_rounds, search_subcluster=True, device = device)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(\"Took {} seconds to train\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta, c_meta_hist, d_sens_hist, losses_train_hist_list, best_epos_list, C_VAE_init_losses, D_VAE_init_losses, c_latent_list, d_latent_list = fit_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_hat = CDPmodel.predict(c_data, d_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_hat = cdr_hat\n",
    "\n",
    "cdr_train_rslt = cdr.copy()\n",
    "cdr_train_rslt['c_name'] = cdr_train_rslt.index.values\n",
    "cdr_train_rslt = pd.melt(cdr_train_rslt, id_vars='c_name', value_vars=None, var_name=None, value_name='value', col_level=None)\n",
    "cdr_train_rslt = cdr_train_rslt.rename(columns={'variable':'d_name', 'value':'cdr'})\n",
    "\n",
    "cdr_train_rslt = pd.merge(cdr_train_rslt, cdr_train_hat, on=['c_name', 'd_name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Binary cross entropy\n",
    "cdr_train_rslt_noNA = cdr_train_rslt.dropna(subset=['cdr_hat', 'cdr'])\n",
    "binary_cross_entropy_train = log_loss(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat'])\n",
    "print(f\"Binary cross entropy: {round(binary_cross_entropy_train,4)}\")\n",
    "\n",
    "\n",
    "# Area Under the Curve (AUC) for a Receiver Operating Characteristic (ROC) \n",
    "roc_auc = roc_auc_score(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat'])\n",
    "print(\"ROC AUC:\", round(roc_auc, 4))\n",
    "\n",
    "# confusion_ atrix\n",
    "cdr_train_rslt_noNA['cdr_hat_bnr'] = (cdr_train_rslt_noNA['cdr_hat'] > 0.5).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat_bnr'])\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"\\nTrue Positive:  {tp} ({(tp / (tp + fn)) * 100:.2f} %)\")\n",
    "print(f\"False Negative: {fn} ({(fn / (fn + tp)) * 100:.2f} %)\")\n",
    "\n",
    "print(f\"True Negative:  {tn} ({(tn / (tn + fp)) * 100:.2f} %)\")\n",
    "print(f\"False Positive: {fp} ({(fp / (fp + tn)) * 100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data\n",
    "cdr_hat.to_csv(os.path.join(data_folder, c_type_str + \"/GDSC_\" + c_type_str + \"_cdr_hat.csv\"), index=True)\n",
    "\n",
    "for k_itr in CDPmodel.which_non_empty_cluster:\n",
    "    c_latent_k = pd.DataFrame(c_latent_list[k_itr][n_rounds-1])\n",
    "    c_latent_k.index = c_data.index\n",
    "    c_latent_k.to_csv(os.path.join(data_folder, c_type_str + \"/GDSC_\" + c_type_str + f\"_c_latent_cluster{k_itr}.csv\"), index=True)\n",
    "\n",
    "    d_latent_k = pd.DataFrame(d_latent_list[k_itr][n_rounds-1])\n",
    "    d_latent_k.index = d_data.index\n",
    "    d_latent_k.to_csv(os.path.join(data_folder, c_type_str + \"/GDSC_\" + c_type_str + f\"_d_latent_cluster{k_itr}.csv\"), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_hat = CDPmodel.predict(c_data, d_data)\n",
    "\n",
    "cdr_train_rslt = cdr.copy()\n",
    "cdr_train_rslt['c_name'] = cdr_train_rslt.index.values\n",
    "cdr_train_rslt = pd.melt(cdr_train_rslt, id_vars='c_name', value_vars=None, var_name=None, value_name='value', col_level=None)\n",
    "cdr_train_rslt = cdr_train_rslt.rename(columns={'variable':'d_name', 'value':'cdr'})\n",
    "\n",
    "\n",
    "cdr_train_rslt = pd.merge(cdr_train_rslt, cdr_train_hat, on=['c_name', 'd_name'], how='outer')\n",
    "\n",
    "cdr_train_rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cancer clustering before:')\n",
    "print(c_meta_hist.code.value_counts())\n",
    "print('Cancer clustering after:')\n",
    "print(c_meta_hist.code_latest.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta_train_tmp = c_meta.loc[:, ['code']]\n",
    "c_meta_train_tmp['c_name'] = c_meta_train_tmp.index.values.astype(str)\n",
    "c_meta_train_tmp = c_meta_train_tmp.rename(columns={'code':'cluster_init'})\n",
    "\n",
    "cdr_train_rslt_tmp = cdr_train_rslt[['c_name', 'cluster']]\n",
    "cdr_train_rslt_tmp = cdr_train_rslt_tmp.drop_duplicates()\n",
    "cdr_train_rslt_tmp['c_name'] = cdr_train_rslt_tmp['c_name'].astype(str)\n",
    "\n",
    "cdr_train_rslt_cluster = pd.merge(cdr_train_rslt_tmp, c_meta_train_tmp, on='c_name', how='left')\n",
    "\n",
    "print(\"CD-bicluster:\")\n",
    "print(pd.crosstab(cdr_train_rslt_cluster['cluster_init'], cdr_train_rslt_cluster['cluster']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_rslt_tmp = cdr_train_rslt[['c_name', 'c_cluster']]\n",
    "cdr_train_rslt_tmp = cdr_train_rslt_tmp.drop_duplicates()\n",
    "cdr_train_rslt_tmp['c_name'] = cdr_train_rslt_tmp['c_name'].astype(str)\n",
    "\n",
    "cdr_train_rslt_cluster = pd.merge(cdr_train_rslt_tmp, c_meta_train_tmp, on='c_name', how='left')\n",
    "\n",
    "print(\"Cancer cluster:\")\n",
    "print(pd.crosstab(cdr_train_rslt_cluster['cluster_init'], cdr_train_rslt_cluster['c_cluster']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sens_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sensitive to clusters before:')\n",
    "print(d_sens_hist.sensitive_k.value_counts())\n",
    "print('Sensitive to clusters after:')\n",
    "print(d_sens_hist.sensitive_k_latest.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "from visuals import *\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_hat_wide = cdr_train_hat.pivot(index='c_name', columns='d_name', values='cdr_hat')\n",
    "cdr_train_hat_wide = cdr_train_hat_wide.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "c_names = [] \n",
    "for k in CDPmodel.which_non_empty_cluster:\n",
    "    c_names_k = CDPmodel.c_name_clusters_in_trainnig[k]\n",
    "    c_names.extend(CDPmodel.c_name_clusters_in_trainnig[k])\n",
    "\n",
    "c_names_in_cluster = [c_name for c_name in c_names if c_name in cdr_train_hat_wide.index]\n",
    "c_names_not_cluster = [c_name for c_name in cdr_train_hat_wide.index if c_name not in c_names]\n",
    "c_names = c_names_in_cluster\n",
    "c_names.extend(c_names_not_cluster)\n",
    "\n",
    "\n",
    "cdr_train_hat_wide = cdr_train_hat_wide.loc[c_names]\n",
    "\n",
    "d_names = []\n",
    "for k in CDPmodel.which_non_empty_cluster:\n",
    "    d_names.extend(CDPmodel.d_name_clusters_in_trainnig[k])\n",
    "d_names_not_cluster = [col for col in cdr_train_hat_wide.columns if col not in d_names]\n",
    "d_names.extend(d_names_not_cluster)\n",
    "cdr_train_hat_wide = cdr_train_hat_wide[d_names]\n",
    "\n",
    "sns.heatmap(\n",
    "        cdr_train_hat_wide, \n",
    "        annot=False, \n",
    "        cmap='PiYG',\n",
    "        # ax=axs[m],\n",
    "        xticklabels=True, yticklabels=False)\n",
    "cmap_custom = LinearSegmentedColormap.from_list(\n",
    "    'custom', [(0, 'white'), (1, 'green')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_save_path = 'results/images/GDSC/GDSC_' + c_type_str + '_c_latent'\n",
    "plot_c_PCA_latent(c_data, n_rounds, fit_returns, model=CDPmodel, plots_save_path=plots_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_save_path = 'results/images/GDSC/GDSC_' + c_type_str + '_d_latent'\n",
    "plot_d_PCA_latent(d_data, n_rounds, fit_returns, model=CDPmodel, plots_save_path=plots_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(CDPmodel.K):\n",
    "    print(f'k = {k}:')\n",
    "    for b in range(n_rounds):\n",
    "        print(f'round {b}:')\n",
    "        plot_training_losses_train_test_2cols(losses_train_hist_list[k][b], best_epoch_1round = best_epos_list[k][b],\n",
    "                                              plot_save_path=f'results/images/GDSC/GDSC_' + c_type_str + '_losses_k{k}_b{b}.png')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
