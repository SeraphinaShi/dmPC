{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinashi/Desktop/DataFusion/DrugResponse_Omics_Molecules'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "import git \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_root():\n",
    "    return Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "root = get_project_root()\n",
    "\n",
    "os.chdir(root)\n",
    "os.getcwd()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = \"images/simulation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages, models, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.13.1\n",
      "orig num threads: 4\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('pytorch version:', torch.__version__)\n",
    "print('orig num threads:', torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from trainers import *\n",
    "from losses import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_folder = \"data/simulations\"\n",
    "RNAseq = pd.read_csv(os.path.join(simu_folder, \"simu1_RNAseq.csv\"), index_col = 0)\n",
    "RNAseq_meta = pd.read_csv(os.path.join(simu_folder, \"simu1_RNAseq_meta.csv\"), index_col = 0)\n",
    "d_fp = pd.read_csv(os.path.join(simu_folder, \"simu1_d_fp.csv\"), index_col = 0)\n",
    "cdr = pd.read_csv(os.path.join(simu_folder, \"simu1_cdr.csv\"), index_col = 0)\n",
    "\n",
    "\n",
    "c_meta, meta_map = get_CCL_meta_codes(RNAseq.columns.values, RNAseq_meta)\n",
    "print(f\"Cancer type coding map: {meta_map}\")\n",
    "print(f\"Count of each coded cancer type:\")\n",
    "print(c_meta['code'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = RNAseq.T\n",
    "c_meta = c_meta\n",
    "\n",
    "d_data = d_fp.T\n",
    "\n",
    "cdr = cdr\n",
    "cdr.index = cdr.index.astype(\"str\")\n",
    "cdr_org = cdr.copy()\n",
    "\n",
    "cdr['c_name'] = cdr.index.values\n",
    "cdr = pd.melt(cdr, id_vars='c_name', value_vars=None,\n",
    "              var_name=None, value_name='value', col_level=None)\n",
    "cdr = cdr.rename(columns={'variable':'d_name', 'value':'cdr'})\n",
    "cdr_all = cdr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    valid_size = 0.1 #@param {type: \"float\"}\n",
    "\n",
    "    n_epochs = 100 #@param {type: \"integer\"}\n",
    "    batch_size = 50 #@param {type: \"integer\"}\n",
    "    lr = 0.01 #@param {type: \"float\"}\n",
    "    \n",
    "    c_cluster_distance_weight = 100 #@param {type: \"float\"}\n",
    "    d_cluster_distance_weight = 100 #@param {type: \"float\"}\n",
    "    predict_loss_weight = 100 #@param {type: \"float\"}\n",
    "    \n",
    "    c_save_path = 'data/model_fits/c_vae.pkl' #@param\n",
    "    d_save_path = 'data/model_fits/d_vae.pkl' #@param\n",
    "    \n",
    "    c_p_save_path = 'data/model_fits/c_vae_predictor.pkl' #@param\n",
    "    d_p_save_path = 'data/model_fits/d_vae_predictor.pkl' #@param\n",
    "    \n",
    "\n",
    "class CDPModel_sub_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    # c_VAE\n",
    "    c_input_dim = 0 #@param {type: \"integer\"}\n",
    "    c_h_dims = [64] #@param {type: \"vactor\"}\n",
    "    c_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # d_VAE\n",
    "    d_input_dim = 0 #@param {type: \"integer\"}\n",
    "    d_h_dims = [64]  #@param {type: \"vactor\"}\n",
    "    d_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # predictor\n",
    "    p_sec_dim = 16 #@param {type: \"integer\"}\n",
    "    p_h_dims = [p_sec_dim*2, 16]  #@param {type: \"vactor\"}\n",
    "    \n",
    "    # all\n",
    "    drop_out = 0  #@param {type: \"float\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Train_Args()\n",
    "\n",
    "K = len(c_meta['code'].unique())\n",
    "\n",
    "CDPmodel_args = CDPModel_sub_Args()\n",
    "CDPmodel_args['c_input_dim'] = c_data.shape[1] \n",
    "CDPmodel_args['d_input_dim'] = d_data.shape[1]\n",
    "\n",
    "if CDPmodel_args['c_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nCancer Cell line feature number not specified''')\n",
    "if CDPmodel_args['d_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nDrug feature number not specified''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta_hist = c_meta.copy()\n",
    "d_sens_k_hist = pd.DataFrame({'sensitive': (cdr_org.loc[c_meta_hist.index.values[c_meta_hist.code == k]].mean(axis=0) > 0.5).astype(int)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define C-VAE, D-VAE, and Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'c_input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e34bde48cd84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = CDPmodel_sub(c_input_dim=c_input_dim, c_h_dims=c_h_dims, c_latent_dim=c_latent_dim, \\\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0md_input_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_h_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_h_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_latent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_latent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  p_sec_dim=p_sec_dim, p_h_dims=p_h_dims)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'c_input_dim'"
     ]
    }
   ],
   "source": [
    "model = CDPmodel_sub(c_input_dim=c_input_dim, c_h_dims=c_h_dims, c_latent_dim=c_latent_dim, \\\n",
    "                 d_input_dim=d_input_dim, d_h_dims=d_h_dims, d_latent_dim=d_latent_dim, \\\n",
    "                 p_sec_dim=p_sec_dim, p_h_dims=p_h_dims)\n",
    "\n",
    "CDPmodel = CDPmodel(K, CDPmodel_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train c_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=================================================================================\n",
    "# Train C_VAE\n",
    "##---------------------\n",
    "## prepare data \n",
    "X_train, X_valid = train_test_split(c_data, test_size=valid_size, random_state=42)\n",
    "X_meta_train = get_CCL_meta(X_train.index.values, c_meta)\n",
    "X_meta_valid = get_CCL_meta(X_valid.index.values, c_meta)\n",
    "\n",
    "X_trainTensor = torch.FloatTensor(X_train.values).to(device)\n",
    "X_meta_trainTensor = torch.FloatTensor(X_meta_train.values).to(device)\n",
    "X_validTensor = torch.FloatTensor(X_valid.values).to(device)\n",
    "X_meta_validTensor = torch.FloatTensor(X_meta_valid.values).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_trainTensor, X_meta_trainTensor)\n",
    "valid_dataset = TensorDataset(X_validTensor, X_meta_validTensor)\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_C = {'train':X_trainDataLoader,'val':X_validDataLoader}\n",
    "##---------------------\n",
    "## define optimizer\n",
    "optimizer_e = optim.Adam(model.c_VAE.parameters(), lr=1e-2)\n",
    "exp_lr_scheduler_e = lr_scheduler.ReduceLROnPlateau(optimizer_e)\n",
    "\n",
    "##---------------------\n",
    "## update C_VAE\n",
    "print(f\" a. Training C_VAE, k={k}\")\n",
    "start = time.time()\n",
    "model.c_VAE,train_hist = train_c_VAE(\n",
    "    vae=model.c_VAE,\n",
    "    data_loaders=dataloaders_C,\n",
    "    cluster_label=k,\n",
    "    cluster_distance_weight = c_cluster_distance_weight,\n",
    "    optimizer=optimizer_e,\n",
    "    n_epochs=n_epochs,\n",
    "    scheduler=exp_lr_scheduler_e,\n",
    "    save_path=c_save_path)\n",
    "end = time.time()\n",
    "print(f\"   Running time: {end - start}\")\n",
    "\n",
    "a_losses = get_train_cVAE_hist_df(train_hist, n_epochs, cluster_distance_weight=c_cluster_distance_weight)\n",
    "model.update_cd_vae_predictor_from_CDPmodel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = a_losses\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_train_vector\"], label = \"total loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_val_vector\"], label = \"total loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_train_vector\"], label = \"vae loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_val_vector\"], label = \"vae loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_train_vector\"], label = \"latent distance loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_val_vector\"], label = \"latent distance loss (test)\");\n",
    "plt.title('Cancer VAE losses')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=================================================================================\n",
    "# Cell lines in cluster k with latent space that is not close to the centroid will be dropped from the cluster\n",
    "c_latent = model.c_VAE.encode(torch.from_numpy(c_data.values).float().to(device), repram=False)\n",
    "\n",
    "if any(c_data.index.values == c_meta.index.values):\n",
    "    c_meta = get_CCL_meta(c_data.index.values, c_meta)\n",
    "    \n",
    "idx_cluster = c_meta.code == k\n",
    "\n",
    "c_cluster_latent = c_latent[idx_cluster]\n",
    "c_centroid = c_cluster_latent.mean(dim=0)\n",
    "\n",
    "c_cluster_distances = torch.cdist(c_cluster_latent, c_centroid.view(1, -1))\n",
    "c_outlier_idx = find_outliers_IQR(c_cluster_distances)[0]\n",
    "\n",
    "idx_cluster_updated = idx_cluster.copy()\n",
    "idx_cluster_updated[c_outlier_idx] = False\n",
    "\n",
    "c_meta.code[idx_cluster] = -1\n",
    "c_meta.code[idx_cluster_updated] = k\n",
    "\n",
    "c_meta_hist['code_1_b'] = c_meta.code\n",
    "\n",
    "print(f\" b. {sum(idx_cluster) - sum(idx_cluster_updated)} cancer cell line(s) dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train d_vae and predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c=================================================================================\n",
    "# Train D_VAE and predictor\n",
    "##---------------------\n",
    "## prepare data\n",
    "### cluster K cell line latent space \n",
    "c_latent = pd.DataFrame(c_latent[idx_cluster_updated].detach().numpy(), index=c_data.index[idx_cluster_updated])\n",
    "\n",
    "### all drugs \n",
    "d_data = d_data\n",
    "\n",
    "### corresponding cdr\n",
    "cdr_k = cdr_all.loc[cdr_all.c_name.isin(c_latent.index.values)]\n",
    "\n",
    "##---------------------\n",
    "## train, test split\n",
    "Y_train, Y_valid = train_test_split(cdr_k, test_size=valid_size, random_state=42)\n",
    "\n",
    "c_meta_train = get_CCL_meta(Y_train.c_name, c_meta)\n",
    "c_meta_valid = get_CCL_meta(Y_valid.c_name, c_meta)\n",
    "\n",
    "c_latent_train = c_latent.loc[Y_train.c_name.astype(str)]\n",
    "c_latent_valid = c_latent.loc[Y_valid.c_name.astype(str)]\n",
    "\n",
    "d_data_train = d_data.loc[Y_train.d_name]\n",
    "d_data_valid = d_data.loc[Y_valid.d_name]\n",
    "\n",
    "##---------------------\n",
    "## Construct datasets and data loaders\n",
    "Y_trainTensor = torch.FloatTensor(Y_train.drop(['c_name','d_name'], axis=1).values).to(device)\n",
    "c_meta_trainTensor = torch.FloatTensor(c_meta_train.values).to(device)\n",
    "c_latent_trainTensor = torch.FloatTensor(c_latent_train.values).to(device)\n",
    "d_data_trainTensor = torch.FloatTensor(d_data_train.values).to(device)\n",
    "\n",
    "Y_validTensor = torch.FloatTensor(Y_valid.drop(['c_name','d_name'], axis=1).values).to(device)\n",
    "c_meta_validTensor = torch.FloatTensor(c_meta_valid.values).to(device)\n",
    "c_latent_validTensor = torch.FloatTensor(c_latent_valid.values).to(device)\n",
    "d_data_validTensor = torch.FloatTensor(d_data_valid.values).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(Y_trainTensor, c_meta_trainTensor, c_latent_trainTensor, d_data_trainTensor)\n",
    "valid_dataset = TensorDataset(Y_validTensor, c_meta_validTensor, c_latent_validTensor, d_data_validTensor)\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_DP = {'train':X_trainDataLoader,'val':X_validDataLoader}\n",
    "\n",
    "##---------------------\n",
    "## define optimizer\n",
    "optimizer_e = optim.Adam(model.d_vae_predictor.parameters(), lr=1e-2)\n",
    "exp_lr_scheduler_e = lr_scheduler.ReduceLROnPlateau(optimizer_e)\n",
    "\n",
    "##---------------------\n",
    "## update D_VAE and predictor\n",
    "print(f\" c. Training D_VAE and Predictor, k={k}\")\n",
    "start = time.time()\n",
    "model.d_vae_predictor, loss_train = train_d_vae_predictor(\n",
    "    d_vae_predictor=model.d_vae_predictor,\n",
    "    data_loaders=dataloaders_DP,\n",
    "    cluster_distance_weight = d_cluster_distance_weight,\n",
    "    predict_loss_weight = predict_loss_weight,\n",
    "    optimizer=optimizer_e,\n",
    "    n_epochs=n_epochs,\n",
    "    scheduler=exp_lr_scheduler_e,\n",
    "    save_path = d_p_save_path)\n",
    "end = time.time()\n",
    "print(f\"   Running time: {end - start}\")\n",
    "\n",
    "c_losses = get_train_VAE_predictor_hist_df(loss_train, n_epochs, cluster_distance_weight=c_cluster_distance_weight, predict_loss_weight=predict_loss_weight)\n",
    "\n",
    "##---------------------\n",
    "## update D_VAE and predictor\n",
    "model.update_CDPmodel_from_d_vae_predictor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = c_losses\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_train_vector\"], label = \"total loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_val_vector\"], label = \"total loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_train_vector\"], label = \"vae loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_val_vector\"], label = \"vae loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_train_vector\"], label = \"latent distance loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_val_vector\"], label = \"latent distance loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"prediction_loss_train_vector\"], label = \"prediction loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"prediction_loss_val_vector\"], label = \"prediction loss (test)\");\n",
    "plt.title('Cancer VAE losses')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d=================================================================================\n",
    "# Drugs with predicted sensitive outcome is assigned to the K-th cluster. Then drugs in cluster k with latent space that is not close to the centroid will be dropped from the cluster.\n",
    "d_latentTensor = model.d_VAE.encode(torch.from_numpy(d_data.loc[cdr_k.d_name].values).float().to(device), repram=False)\n",
    "c_latentTensor = torch.FloatTensor(c_latent.loc[cdr_k.c_name.astype(str)].values).to(device)\n",
    "y_hatTensor = model.predictor(c_latentTensor, d_latentTensor)\n",
    "\n",
    "y_hat = y_hatTensor.detach().view(-1)\n",
    "y_hat = y_hat.numpy()\n",
    "cdr_k_hat = pd.DataFrame({'d_name':cdr_k.d_name, 'c_name':cdr_k.c_name, 'cdr':y_hat})\n",
    "\n",
    "d_sens_k = get_D_sensitive_codes(cdr_k_hat)\n",
    "d_name_sensitive_k = d_sens_k.index.values[d_sens_k.sensitive == 1]\n",
    "\n",
    "d_sensitive_latent = model.d_VAE.encode(torch.from_numpy(d_data.loc[d_name_sensitive_k].values).float().to(device), repram=False)\n",
    "d_centroid = d_sensitive_latent.mean(dim=0)\n",
    "\n",
    "d_sensitive_distances = torch.cdist(d_sensitive_latent, d_centroid.view(1, -1))\n",
    "d_outlier_idx = find_outliers_IQR(d_sensitive_distances)[0]\n",
    "\n",
    "d_sens_k.sensitive[d_outlier_idx] = 0\n",
    "\n",
    "d_sens_k_hist['sensitive_1_d'] = d_sens_k.sensitive\n",
    "\n",
    "print(f\" d. {sum(d_sens_k_hist.sensitive) - sum(d_sens_k.sensitive)} drug(s) dropped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train D_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e=================================================================================\n",
    "##---------------------\n",
    "## prepare data \n",
    "X_train, X_valid = train_test_split(d_data, test_size=valid_size, random_state=42)\n",
    "X_meta_train = get_D_sensitive(X_train.index.values, d_sens_k)\n",
    "X_meta_valid = get_D_sensitive(X_valid.index.values, d_sens_k)\n",
    "\n",
    "X_trainTensor = torch.FloatTensor(X_train.values).to(device)\n",
    "X_meta_trainTensor = torch.FloatTensor(X_meta_train.values).to(device)\n",
    "X_validTensor = torch.FloatTensor(X_valid.values).to(device)\n",
    "X_meta_validTensor = torch.FloatTensor(X_meta_valid.values).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_trainTensor, X_meta_trainTensor)\n",
    "valid_dataset = TensorDataset(X_validTensor, X_meta_validTensor)\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_D = {'train':X_trainDataLoader,'val':X_validDataLoader}\n",
    "##---------------------\n",
    "## define optimizer\n",
    "optimizer_e = optim.Adam(model.d_VAE.parameters(), lr=1e-2)\n",
    "exp_lr_scheduler_e = lr_scheduler.ReduceLROnPlateau(optimizer_e)\n",
    "\n",
    "##---------------------\n",
    "## update C_VAE\n",
    "print(f\" e. Training D_VAE, k={k}\")\n",
    "start = time.time()\n",
    "model.d_VAE,train_hist = train_d_VAE(\n",
    "    vae=model.d_VAE,\n",
    "    data_loaders=dataloaders_D,\n",
    "    cluster_distance_weight = d_cluster_distance_weight,\n",
    "    optimizer=optimizer_e,\n",
    "    n_epochs=n_epochs,\n",
    "    scheduler=exp_lr_scheduler_e,\n",
    "    save_path=d_save_path)\n",
    "end = time.time()\n",
    "print(f\"   Running time: {end - start}\")\n",
    "\n",
    "e_losses = get_train_dVAE_hist_df(train_hist, n_epochs, cluster_distance_weight=d_cluster_distance_weight)\n",
    "\n",
    "model.update_cd_vae_predictor_from_CDPmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = e_losses\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_train_vector\"], label = \"total loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_val_vector\"], label = \"total loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_train_vector\"], label = \"vae loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_val_vector\"], label = \"vae loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_train_vector\"], label = \"latent distance loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_val_vector\"], label = \"latent distance loss (test)\");\n",
    "plt.title('Drug VAE losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = model.d_VAE.encode(torch.from_numpy(d_data.values).float().to(device), repram=False)\n",
    "mu = mu.detach().numpy()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(mu)\n",
    "\n",
    "components = pca.transform(mu)\n",
    "\n",
    "color_labels =  d_sens_k['sensitive'].unique()\n",
    "color_values = sns.color_palette(\"Set2\", 8)\n",
    "color_map = dict(zip(color_labels, color_values))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(components[:,0],components[:,1], color= d_sens_k['sensitive'].map(color_map))\n",
    "handlelist = [plt.plot([], marker=\"o\", ls=\"\", color=color)[0] for color in color_values]\n",
    "plt.legend(handlelist,color_labels)\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f=================================================================================\n",
    "# Drugs in cluster k with latent space that is not close to the centroid will be dropped from the cluster  \n",
    "d_latent = model.d_VAE.encode(torch.from_numpy(d_data.values).float().to(device), repram=False)\n",
    "\n",
    "if any(d_data.index.values == d_sens_k.index.values):\n",
    "    d_sens_k = get_D_sensitive(d_data.index.values, d_sens_k)\n",
    "    \n",
    "idx_cluster = d_sens_k.sensitive == 1\n",
    "\n",
    "d_cluster_latent = d_latent[idx_cluster]\n",
    "d_centroid = d_cluster_latent.mean(dim=0)\n",
    "\n",
    "d_cluster_distances = torch.cdist(d_cluster_latent, d_centroid.view(1, -1))\n",
    "d_outlier_idx = find_outliers_IQR(d_cluster_distances)[0]\n",
    "\n",
    "idx_cluster_updated = idx_cluster.copy()\n",
    "idx_cluster_updated[d_outlier_idx] = False\n",
    "\n",
    "d_sens_k.sensitive = 0\n",
    "d_sens_k.sensitive[idx_cluster_updated] = 1\n",
    "d_sens_k\n",
    "\n",
    "d_sens_k_hist['sensitive_1_f'] = d_sens_k.sensitive\n",
    "d_sens_k_hist\n",
    "\n",
    "print(f\" f. {sum(idx_cluster) - sum(idx_cluster_updated)} drug(s) dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g=================================================================================\n",
    "# Train C_VAE and predictor \n",
    "\n",
    "##---------------------\n",
    "## prepare data\n",
    "### all cell line data \n",
    "c_data = c_data\n",
    "\n",
    "### cluster K sensitive drug latent space \n",
    "d_latent = pd.DataFrame(d_latent[idx_cluster_updated].detach().numpy(), index=d_data.index[idx_cluster_updated])\n",
    "\n",
    "### corresponding cdr\n",
    "cdr_k = cdr_all.loc[cdr_all.d_name.isin(d_latent.index.values)]\n",
    "\n",
    "\n",
    "##---------------------\n",
    "## train, test split\n",
    "Y_train, Y_valid = train_test_split(cdr_k, test_size=valid_size, random_state=42)\n",
    "\n",
    "c_meta_train = get_CCL_meta(Y_train.c_name, c_meta)\n",
    "c_meta_valid = get_CCL_meta(Y_valid.c_name, c_meta)\n",
    "\n",
    "c_data_train = c_data.loc[Y_train.c_name.astype(str)]\n",
    "c_data_valid = c_data.loc[Y_valid.c_name.astype(str)]\n",
    "\n",
    "d_latent_train = d_latent.loc[Y_train.d_name]\n",
    "d_latent_valid = d_latent.loc[Y_valid.d_name]\n",
    "\n",
    "\n",
    "##---------------------\n",
    "## Construct datasets and data loaders\n",
    "Y_trainTensor = torch.FloatTensor(Y_train.drop(['c_name','d_name'], axis=1).values).to(device)\n",
    "c_meta_trainTensor = torch.FloatTensor(c_meta_train.values).to(device)\n",
    "c_data_trainTensor = torch.FloatTensor(c_data_train.values).to(device)\n",
    "d_latent_trainTensor = torch.FloatTensor(d_latent_train.values).to(device)\n",
    "\n",
    "Y_validTensor = torch.FloatTensor(Y_valid.drop(['c_name','d_name'], axis=1).values).to(device)\n",
    "c_meta_validTensor = torch.FloatTensor(c_meta_valid.values).to(device)\n",
    "c_data_validTensor = torch.FloatTensor(c_data_valid.values).to(device)\n",
    "d_latent_validTensor = torch.FloatTensor(d_latent_valid.values).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(Y_trainTensor, c_meta_trainTensor, c_data_trainTensor, d_latent_trainTensor)\n",
    "valid_dataset = TensorDataset(Y_validTensor, c_meta_validTensor, c_data_validTensor, d_latent_validTensor)\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_CP = {'train':X_trainDataLoader,'val':X_validDataLoader}\n",
    "\n",
    "##---------------------\n",
    "## define optimizer\n",
    "optimizer_e = optim.Adam(model.c_vae_predictor.parameters(), lr=1e-2)\n",
    "exp_lr_scheduler_e = lr_scheduler.ReduceLROnPlateau(optimizer_e)\n",
    "\n",
    "##---------------------\n",
    "## update C_VAE and predictor\n",
    "print(f\" g. Training C_VAE and Predictor, k={k}\")\n",
    "start = time.time()\n",
    "model.c_vae_predictor, loss_train = train_c_vae_predictor(\n",
    "    c_vae_predictor=model.c_vae_predictor,\n",
    "    data_loaders=dataloaders_CP,\n",
    "    cluster_label = k,\n",
    "    cluster_distance_weight = d_cluster_distance_weight,\n",
    "    predict_loss_weight = predict_loss_weight,\n",
    "    optimizer=optimizer_e,\n",
    "    n_epochs=n_epochs,\n",
    "    scheduler=exp_lr_scheduler_e,\n",
    "    save_path = c_p_save_path)\n",
    "end = time.time()\n",
    "print(f\"   Running time: {end - start}\")\n",
    "\n",
    "g_losses = get_train_VAE_predictor_hist_df(loss_train, n_epochs, cluster_distance_weight=c_cluster_distance_weight, predict_loss_weight=predict_loss_weight)\n",
    "\n",
    "\n",
    "##---------------------\n",
    "## update D_VAE and predictor\n",
    "model.update_CDPmodel_from_c_vae_predictor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = g_losses\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_train_vector\"], label = \"total loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"loss_val_vector\"], label = \"total loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_train_vector\"], label = \"vae loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"vae_loss_val_vector\"], label = \"vae loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_train_vector\"], label = \"latent distance loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"latent_d_loss_val_vector\"], label = \"latent distance loss (test)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"prediction_loss_train_vector\"], label = \"prediction loss (train)\");\n",
    "plt.plot(losses[\"epoch\"], losses[\"prediction_loss_val_vector\"], label = \"prediction loss (test)\");\n",
    "plt.title('Cancer VAE losses')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=================================================================================\n",
    "# Cell lines with predicted sensitive outcome is assigned to the K-th cluster. Again, cell lines in cluster k with latent space that is not close to the centroid will be dropped from the cluster.\n",
    "c_latentTensor = model.c_VAE.encode(torch.from_numpy(c_data.loc[cdr_k.c_name].values).float().to(device), repram=False)\n",
    "d_latentTensor = torch.FloatTensor(d_latent.loc[cdr_k.d_name.astype(str)].values).to(device)\n",
    "y_hatTensor = model.predictor(c_latentTensor, d_latentTensor)\n",
    "\n",
    "y_hat = y_hatTensor.detach().view(-1)\n",
    "y_hat = y_hat.numpy()\n",
    "cdr_k_hat = pd.DataFrame({'d_name':cdr_k.d_name, 'c_name':cdr_k.c_name, 'cdr':y_hat})\n",
    "\n",
    "c_sens_k = get_C_sensitive_codes(cdr_k_hat)\n",
    "c_name_sensitive_k = c_sens_k.index.values[c_sens_k.sensitive == 1]\n",
    "\n",
    "c_sensitive_latent = model.c_VAE.encode(torch.from_numpy(c_data.loc[c_name_sensitive_k].values).float().to(device), repram=False)\n",
    "c_centroid = c_sensitive_latent.mean(dim=0)\n",
    "\n",
    "c_sensitive_distances = torch.cdist(c_sensitive_latent, c_centroid.view(1, -1))\n",
    "c_outlier_idx = find_outliers_IQR(c_sensitive_distances)[0]\n",
    "\n",
    "c_sens_k.sensitive[c_outlier_idx] = 0\n",
    "\n",
    "idx_cluster_updated = c_sens_k.sensitive == 1\n",
    "idx_cluster = c_meta.code == k\n",
    "\n",
    "c_meta.loc[idx_cluster, 'code'] = -1\n",
    "c_meta.loc[idx_cluster_updated, 'code'] = k\n",
    "\n",
    "c_meta_hist['code_1_h'] = c_meta.code\n",
    "\n",
    "print(f\" d. {sum(idx_cluster) - sum(idx_cluster_updated)} cancer cell line(s) dropped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_hist = [a_losses, c_losses, e_losses, g_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta.code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cluster_c_names = c_meta.index.values[c_meta.code==k]\n",
    "k_cluster_c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sens_k_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sens_k.sensitive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cluster_d_names = d_sens_k.index.values[d_sens_k.sensitive==1]\n",
    "k_cluster_d_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
