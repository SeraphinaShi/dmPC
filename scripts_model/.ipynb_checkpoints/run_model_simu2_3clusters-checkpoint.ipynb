{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinashi/Desktop/DataFusion/DrugResponse_Omics_Molecules'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we're in the correct working directory\n",
    "import os\n",
    "import git \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_root():\n",
    "    return Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "root = get_project_root()\n",
    "\n",
    "os.chdir(root)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = \"results/images/simulations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages, models, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seraphinashi/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.13.1\n",
      "orig num threads: 4\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('pytorch version:', torch.__version__)\n",
    "print('orig num threads:', torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from trainers import *\n",
    "from losses import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_folder = \"data/simulations\"\n",
    "RNAseq = pd.read_csv(os.path.join(simu_folder, \"simu2_RNAseq.csv\"), index_col = 0)\n",
    "RNAseq_meta = pd.read_csv(os.path.join(simu_folder, \"simu2_RNAseq_meta.csv\"), index_col = 0)\n",
    "d_fp = pd.read_csv(os.path.join(simu_folder, \"simu2_d_fp.csv\"), index_col = 0)\n",
    "cdr = pd.read_csv(os.path.join(simu_folder, \"simu2_cdr.csv\"), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNAseq_meta['C_type'] = RNAseq_meta['C_type'].replace('grp3', 'grp0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer type coding map: \n",
      "  C_type  code  count\n",
      "0   grp0     0     62\n",
      "4   grp1     1     35\n",
      "8   grp2     2     41\n"
     ]
    }
   ],
   "source": [
    "c_data = RNAseq.T\n",
    "\n",
    "# originally\n",
    "c_meta, meta_map = get_CCL_meta_codes(RNAseq.columns.values, RNAseq_meta)\n",
    "\n",
    "print(f\"Cancer type coding map: \")\n",
    "print(meta_map)\n",
    "\n",
    "d_data = d_fp.T\n",
    "\n",
    "cdr = cdr\n",
    "cdr.index = cdr.index.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster = 3\n",
    "\n",
    "# only two groups\n",
    "two_grp = False\n",
    "if two_grp:\n",
    "    num_cluster = 2\n",
    "    RNAseq_meta.loc[RNAseq_meta.C_type=='grp2', 'C_type'] = 'grp1'\n",
    "    \n",
    "    c_meta_true = c_meta\n",
    "    c_meta, meta_map = get_CCL_meta_codes(RNAseq.columns.values, RNAseq_meta)\n",
    "    print(f\"Cancer type coding map: \")\n",
    "    print(meta_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train, c_test = train_test_split(c_data, test_size=0.15)\n",
    "\n",
    "c_meta_train = get_CCL_meta(c_train.index.values, c_meta)\n",
    "c_meta_test = get_CCL_meta(c_test.index.values, c_meta)\n",
    "\n",
    "cdr_train_idx = np.isin(cdr.index.values, c_train.index.values)\n",
    "cdr_train = cdr[cdr_train_idx]\n",
    "cdr_test = cdr[~cdr_train_idx]\n",
    "\n",
    "if two_grp:\n",
    "    c_meta_train_true = get_CCL_meta(c_train.index.values, c_meta_true)\n",
    "    c_meta_test_true = get_CCL_meta(c_test.index.values, c_meta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "   cdr: (117, 30)\n",
      "   c_data: (117, 355) \n",
      "   d_data: (30, 150)\n",
      "   Number of each initial cancer clusters: \n",
      "\n",
      "code\n",
      "0    54\n",
      "2    33\n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing data:  \n",
      "   cdr: (21, 30)\n",
      "   c_data: (21, 355) \n",
      "   d_data: (30, 150)\n",
      "   Number of each initial cancer clusters: \n",
      "\n",
      "code\n",
      "0    8\n",
      "2    8\n",
      "1    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: \\n   cdr: {cdr_train.shape}\\n   c_data: {c_train.shape} \\n   d_data: {d_data.shape}\")\n",
    "print(f\"   Number of each initial cancer clusters: \\n\")\n",
    "if two_grp:\n",
    "    print(pd.crosstab(c_meta_train_true['code'], c_meta_train['code'], margins=True, margins_name=\"Total\"))\n",
    "else:\n",
    "    print(c_meta_train['code'].value_counts())\n",
    "\n",
    "print(f\"\\nTesting data:  \\n   cdr: {cdr_test.shape}\\n   c_data: {c_test.shape} \\n   d_data: {d_data.shape}\")\n",
    "print(f\"   Number of each initial cancer clusters: \\n\")\n",
    "if two_grp:\n",
    "    print(pd.crosstab(c_meta_test_true['code'], c_meta_test['code'], margins=True, margins_name=\"Total\"))\n",
    "else:\n",
    "    print(c_meta_test['code'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    valid_size = 0.2 #@param {type: \"float\"}\n",
    "\n",
    "    n_epochs = 100 #@param {type: \"integer\"}\n",
    "    batch_size = 50 #@param {type: \"integer\"}\n",
    "    lr = 0.01 #@param {type: \"float\"}\n",
    "    \n",
    "    C_VAE_loss_weight = 0.2 #@param {type: \"float\"}\n",
    "    C_recon_loss_weight = 1 #@param {type: \"float\"}\n",
    "    C_kld_weight = 1 #@param {type: \"float\"}\n",
    "    C_cluster_distance_weight = 150 #@param {type: \"float\"}\n",
    "    C_update_ratio_weight = 100 #@param {type: \"float\"}\n",
    "    \n",
    "    D_VAE_loss_weight = 0.5 #@param {type: \"float\"}\n",
    "    D_recon_loss_weight = 1.5 #@param {type: \"float\"}\n",
    "    D_kld_weight = 1 #@param {type: \"float\"}\n",
    "    D_cluster_distance_weight = 100 #@param {type: \"float\"}\n",
    "    D_update_ratio_weight = 100 #@param {type: \"float\"}\n",
    "    \n",
    "    predict_loss_weight = 1000 #@param {type: \"float\"}\n",
    "    \n",
    "    cVAE_save_path = 'data/model_fits/GDSC_simu_3c_c_vae' #@param\n",
    "    dVAE_save_path = 'data/model_fits/GDSC_simu_3c_d_vae' #@param\n",
    "    \n",
    "    c_p_save_path = 'data/model_fits/GDSC_simu_3c_c_vae_predictor' #@param\n",
    "    d_p_save_path = 'data/model_fits/GDSC_simu_3c_d_vae_predictor' #@param\n",
    "    \n",
    "\n",
    "class CDPModel_sub_Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    # c_VAE\n",
    "    c_input_dim = 0 #@param {type: \"integer\"}\n",
    "    c_h_dims = [64] #@param {type: \"vactor\"}\n",
    "    c_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # d_VAE\n",
    "    d_input_dim = 0 #@param {type: \"integer\"}\n",
    "    d_h_dims = [64]  #@param {type: \"vactor\"}\n",
    "    d_latent_dim = 32 #@param {type: \"integer\"}\n",
    "\n",
    "    # predictor\n",
    "    p_sec_dim = 16 #@param {type: \"integer\"}\n",
    "    p_h_dims = [p_sec_dim*2, 16]  #@param {type: \"vactor\"}\n",
    "    \n",
    "    # all\n",
    "    drop_out = 0  #@param {type: \"float\"}\n",
    "    \n",
    "    # sensitive threshold\n",
    "    sens_cutoff = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Train_Args()\n",
    "\n",
    "K = len(c_meta['code'].unique())\n",
    "\n",
    "CDPmodel_args = CDPModel_sub_Args()\n",
    "CDPmodel_args['c_input_dim'] = c_data.shape[1] \n",
    "CDPmodel_args['d_input_dim'] = d_data.shape[1]\n",
    "\n",
    "if CDPmodel_args['c_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nCancer Cell line feature number not specified''')\n",
    "if CDPmodel_args['d_input_dim'] <= 0:\n",
    "  warnings.warn(\n",
    "      '''\\nDrug feature number not specified''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Initialize C-VAE:\n",
      "        Best epoc with test loss: epoch 93\n",
      "        Running time: 0.5254511833190918\n",
      "=> Initialize D-VAE:\n",
      "        Best epoc with test loss: epoch 53\n",
      "        Running time: 0.21306538581848145\n",
      "=> round 0 <==================================\n",
      "------------k = 0-------------------\n",
      " - Training CDP model with k = 0\n",
      "['d_g3_1' 'd_g3_2' 'd_g3_3' 'd_g3_4' 'd_g3_5' 'd_g3_6' 'd_g3_7' 'd_g3_8'\n",
      " 'd_g3_9' 'd_g3_10']\n",
      "['713885' '688023' '910937' '753610' '907295' '1240186' '1240193' '910692'\n",
      " '908481' '906808' '688018' '753605' '688006' '753588' '908469' '688013'\n",
      " '1297438' '909194' '713880' '1299062' '1240189' '1298349' '688007'\n",
      " '1297439' '753551' '908480' '688015' '713899' '687997' '753599' '753547'\n",
      " '688010' '688011' '910899' '1240192' '724872' '687985' '687983' '1331055'\n",
      " '753582' '753597' '908483' '753589' '688027' '908468' '688022' '688014'\n",
      " '753564' '1330972' '753594' '924241' '688026' '687995' '688021']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 50\n",
      "        Running time: 18.68574810028076\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 90\n",
      "        Running time: 13.782763957977295\n",
      "   d. 54 cancer cell line(s) in the cluster\n",
      "------------k = 1-------------------\n",
      " - Training CDP model with k = 1\n",
      "['d_g1_1' 'd_g1_2' 'd_g1_3' 'd_g1_4' 'd_g1_5' 'd_g1_6' 'd_g1_7' 'd_g1_8'\n",
      " 'd_g1_9' 'd_g1_10']\n",
      "['1290908' '687812' '687819' '1322212' '1330973' '1240142' '724878'\n",
      " '687802' '724873' '906791' '1298538' '908460' '724879' '905967' '1298223'\n",
      " '908465' '1298347' '1298350' '687777' '1247873' '687815' '1298226'\n",
      " '908443' '905972' '1240183' '724859' '1240190' '724874' '724834' '687787']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 85\n",
      "        Running time: 9.999638795852661\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 93\n",
      "        Running time: 13.229815006256104\n",
      "   d. 30 cancer cell line(s) in the cluster\n",
      "------------k = 2-------------------\n",
      " - Training CDP model with k = 2\n",
      "['d_g2_1' 'd_g2_2' 'd_g2_3' 'd_g2_4' 'd_g2_5' 'd_g2_6' 'd_g2_7' 'd_g2_8'\n",
      " 'd_g2_9' 'd_g2_10']\n",
      "['1240145' '722045' '1298537' '753608' '687798' '1298348' '724866'\n",
      " '687807' '905949' '908472' '908476' '722058' '687821' '1240143' '687794'\n",
      " '909721' '1240185' '910399' '722066' '713869' '687800' '905942' '1503370'\n",
      " '753592' '687816' '753554' '924244' '753600' '905970' '1240146' '722046'\n",
      " '910931' '909728']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 27\n",
      "        Running time: 11.106831312179565\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 53\n",
      "        Running time: 13.428443908691406\n",
      "   d. 33 cancer cell line(s) in the cluster\n",
      "=> round 1 <==================================\n",
      "------------k = 0-------------------\n",
      " - Training CDP model with k = 0\n",
      "['d_g3_1' 'd_g3_2' 'd_g3_3' 'd_g3_4' 'd_g3_5' 'd_g3_6' 'd_g3_7' 'd_g3_8'\n",
      " 'd_g3_9' 'd_g3_10']\n",
      "['713885' '688023' '910937' '753610' '907295' '1240186' '1240193' '910692'\n",
      " '908481' '906808' '688018' '753605' '688006' '753588' '908469' '688013'\n",
      " '1297438' '909194' '713880' '1299062' '1240189' '1298349' '688007'\n",
      " '1297439' '753551' '908480' '688015' '713899' '687997' '753599' '753547'\n",
      " '688010' '688011' '910899' '1240192' '724872' '687985' '687983' '1331055'\n",
      " '753582' '753597' '908483' '753589' '688027' '908468' '688022' '688014'\n",
      " '753564' '1330972' '753594' '924241' '688026' '687995' '688021']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 79\n",
      "        Running time: 18.07154893875122\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 85\n",
      "        Running time: 13.96156907081604\n",
      "   d. 54 cancer cell line(s) in the cluster\n",
      "------------k = 1-------------------\n",
      " - Training CDP model with k = 1\n",
      "['d_g1_1' 'd_g1_2' 'd_g1_3' 'd_g1_4' 'd_g1_5' 'd_g1_6' 'd_g1_7' 'd_g1_8'\n",
      " 'd_g1_9' 'd_g1_10']\n",
      "['1290908' '687812' '687819' '1322212' '1330973' '1240142' '724878'\n",
      " '687802' '724873' '906791' '1298538' '908460' '724879' '905967' '1298223'\n",
      " '908465' '1298347' '1298350' '687777' '1247873' '687815' '1298226'\n",
      " '908443' '905972' '1240183' '724859' '1240190' '724874' '724834' '687787']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 83\n",
      "        Running time: 10.513910055160522\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 96\n",
      "        Running time: 14.253373146057129\n",
      "   d. 30 cancer cell line(s) in the cluster\n",
      "------------k = 2-------------------\n",
      " - Training CDP model with k = 2\n",
      "['d_g2_1' 'd_g2_2' 'd_g2_3' 'd_g2_4' 'd_g2_5' 'd_g2_6' 'd_g2_7' 'd_g2_8'\n",
      " 'd_g2_9' 'd_g2_10']\n",
      "['1240145' '722045' '1298537' '753608' '687798' '1298348' '724866'\n",
      " '687807' '905949' '908472' '908476' '722058' '687821' '1240143' '687794'\n",
      " '909721' '1240185' '910399' '722066' '713869' '687800' '905942' '1503370'\n",
      " '753592' '687816' '753554' '924244' '753600' '905970' '1240146' '722046'\n",
      " '910931' '909728']\n",
      "   a. Training D_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 98\n",
      "        Running time: 11.904556035995483\n",
      "   b. 10 sensitive drug(s)\n",
      "   c. Training C_VAE and Predictor\n",
      "        Best epoc with test loss: epoch 40\n",
      "        Running time: 13.488013982772827\n",
      "   d. 33 cancer cell line(s) in the cluster\n"
     ]
    }
   ],
   "source": [
    "CDPmodel = CDPmodel(K, CDPmodel_args)\n",
    "\n",
    "n_rounds = 2\n",
    "returns = CDPmodel.fit(c_train, c_meta_train, d_data, cdr_train, train_args, n_rounds=n_rounds, device = device)\n",
    "c_meta, c_meta_hist, d_sens_hist, losses_train_hist_list, best_epos_list, C_VAE_init_losses, D_VAE_init_losses, c_latent_list, d_latent_list = returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'banana', 'apple', 'cherry']\n",
      "{'date': 0, 'banana': 1, 'apple': 2, 'cherry': 3}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample multiple string lists with duplicates\n",
    "string_list1 = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
    "string_list2 = [\"banana\", \"date\", \"fig\", \"grape\"]\n",
    "\n",
    "# Aggregate all unique strings from the multiple lists\n",
    "all_strings = list(set(string_list1))\n",
    "\n",
    "print(all_strings)\n",
    "\n",
    "# Create a dictionary to map strings to one-hot indices\n",
    "string_to_index = {string: index for index, string in enumerate(all_strings)}\n",
    "print(string_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 0, 'fig': 1, 'cherry': 2, 'grape': 3, 'date': 4, 'banana': 5}\n",
      "[0, 5, 2, 4]\n",
      "Tensor for string_list1:\n",
      "tensor([0., 5., 2., 4.])\n",
      "Tensor for string_list2:\n",
      "tensor([5., 4., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample multiple string lists with duplicates\n",
    "string_list1 = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
    "string_list2 = [\"banana\", \"date\", \"fig\", \"grape\"]\n",
    "\n",
    "# Aggregate all unique strings from the multiple lists\n",
    "all_strings = list(set(string_list1 + string_list2))\n",
    "\n",
    "# Create a dictionary to map strings to one-hot indices\n",
    "string_to_index = {string: index for index, string in enumerate(all_strings)}\n",
    "print(string_to_index)\n",
    "\n",
    "# Function to perform one-hot encoding for a string list\n",
    "def one_hot_encode(string_list):\n",
    "    encoded_strings = []\n",
    "    for string in string_list:\n",
    "        encoded_strings.append(string_to_index[string])\n",
    "    return encoded_strings\n",
    "\n",
    "# Perform one-hot encoding for each list\n",
    "encoded_list1 = one_hot_encode(string_list1)\n",
    "encoded_list2 = one_hot_encode(string_list2)\n",
    "print(encoded_list1)\n",
    "\n",
    "# Convert the encoded lists into Torch tensors\n",
    "tensor_list1 = torch.tensor(encoded_list1, dtype=torch.float32)\n",
    "tensor_list2 = torch.tensor(encoded_list2, dtype=torch.float32)\n",
    "\n",
    "print(\"Tensor for string_list1:\")\n",
    "print(tensor_list1)\n",
    "\n",
    "print(\"Tensor for string_list2:\")\n",
    "print(tensor_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results and visualizations\n",
    "\n",
    "## 4.1. Prediction:\n",
    "\n",
    "### Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_hat = CDPmodel.predict(c_train, d_data)\n",
    "\n",
    "cdr_train_rslt = cdr_train.copy()\n",
    "cdr_train_rslt['c_name'] = cdr_train_rslt.index.values\n",
    "cdr_train_rslt = pd.melt(cdr_train_rslt, id_vars='c_name', value_vars=None, var_name=None, value_name='value', col_level=None)\n",
    "cdr_train_rslt = cdr_train_rslt.rename(columns={'variable':'d_name', 'value':'cdr'})\n",
    "\n",
    "cdr_train_rslt = pd.merge(cdr_train_rslt, cdr_train_hat, on=['c_name', 'd_name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary cross entropy: 9.866565042668208\n",
      "ROC AUC: 0.6188912630579297\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-92ec263bd92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# confusion_ atrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdr_train_rslt_noNA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cdr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdr_train_rslt_noNA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cdr_hat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Binary cross entropy\n",
    "cdr_train_rslt_noNA = cdr_train_rslt.dropna(subset=['cdr_hat', 'cdr'])\n",
    "binary_cross_entropy_train = log_loss(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat'])\n",
    "print(f\"Binary cross entropy: {binary_cross_entropy_train}\")\n",
    "\n",
    "\n",
    "# Area Under the Curve (AUC) for a Receiver Operating Characteristic (ROC) \n",
    "roc_auc = roc_auc_score(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat'])\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# confusion_ atrix\n",
    "conf_matrix = confusion_matrix(cdr_train_rslt_noNA['cdr'], cdr_train_rslt_noNA['cdr_hat'])\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"\\nTrue Positive:  {tp} ({(tp / (tp + fn)) * 100:.2f} %)\")\n",
    "print(f\"False Negative: {fn} ({(fn / (fn + tp)) * 100:.2f} %)\")\n",
    "\n",
    "print(f\"True Negative:  {tn} ({(tn / (tn + fp)) * 100:.2f} %)\")\n",
    "print(f\"False Positive: {fp} ({(fp / (fp + tn)) * 100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_test_hat = CDPmodel.predict(c_test, d_data)\n",
    "\n",
    "cdr_test_rslt = cdr_test.copy()\n",
    "cdr_test_rslt['c_name'] = cdr_test_rslt.index.values\n",
    "cdr_test_rslt = pd.melt(cdr_test_rslt, id_vars='c_name', value_vars=None, var_name=None, value_name='value', col_level=None)\n",
    "cdr_test_rslt = cdr_test_rslt.rename(columns={'variable':'d_name', 'value':'cdr'})\n",
    "\n",
    "cdr_test_rslt = pd.merge(cdr_test_rslt, cdr_test_hat, on=['c_name', 'd_name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy\n",
    "cdr_test_rslt_noNA = cdr_test_rslt.dropna(subset=['cdr_hat', 'cdr'])\n",
    "binary_cross_entropy_test = log_loss(cdr_test_rslt_noNA['cdr'], cdr_test_rslt_noNA['cdr_hat'])\n",
    "print(f\"Binary cross entropy: {binary_cross_entropy_test}\")\n",
    "\n",
    "# Area Under the Curve (AUC) for a Receiver Operating Characteristic (ROC) \n",
    "roc_auc = roc_auc_score(cdr_test_rslt_noNA['cdr'], cdr_test_rslt_noNA['cdr_hat'])\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# confusion_ atrix\n",
    "cdr_test_rslt_noNA['cdr_hat_bnr'] = (cdr_test_rslt_noNA['cdr_hat'] > 0.5).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(cdr_test_rslt_noNA['cdr'], cdr_test_rslt_noNA['cdr_hat_bnr'])\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"\\nTrue Positive:  {tp} ({(tp / (tp + fn)) * 100:.2f} %)\")\n",
    "print(f\"False Negative: {fn} ({(fn / (fn + tp)) * 100:.2f} %)\")\n",
    "\n",
    "print(f\"True Negative:  {tn} ({(tn / (tn + fp)) * 100:.2f} %)\")\n",
    "print(f\"False Positive: {fp} ({(fp / (fp + tn)) * 100:.2f} %)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Clustering\n",
    "### Trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta_train_tmp = c_meta_train.loc[:, ['code']]\n",
    "c_meta_train_tmp['c_name'] = c_meta_train_tmp.index.values.astype(str)\n",
    "c_meta_train_tmp = c_meta_train_tmp.rename(columns={'code':'cluster_init'})\n",
    "\n",
    "cdr_train_rslt_tmp = cdr_train_rslt[['c_name', 'cluster']]\n",
    "cdr_train_rslt_tmp = cdr_train_rslt_tmp.drop_duplicates()\n",
    "cdr_train_rslt_tmp['c_name'] = cdr_train_rslt_tmp['c_name'].astype(str)\n",
    "\n",
    "cdr_train_rslt_cluster = pd.merge(cdr_train_rslt_tmp, c_meta_train_tmp, on='c_name', how='left')\n",
    "\n",
    "if two_grp:\n",
    "    c_meta_true_tmp = c_meta_true.loc[:, ['code']]\n",
    "    c_meta_true_tmp['c_name'] = c_meta_true_tmp.index.values.astype(str)\n",
    "    c_meta_true_tmp = c_meta_true_tmp.rename(columns={'code':'cluster_true'})\n",
    "\n",
    "    cdr_train_rslt_cluster = pd.merge(cdr_train_rslt_cluster, c_meta_true_tmp, on='c_name', how='left')\n",
    "    \n",
    "    print(pd.crosstab([cdr_train_rslt_cluster['cluster_true'], cdr_train_rslt_cluster['cluster_init']], cdr_train_rslt_cluster['cluster']))\n",
    "else:\n",
    "    print(pd.crosstab(cdr_train_rslt_cluster['cluster_init'], cdr_train_rslt_cluster['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cancer clustering before:')\n",
    "print(c_meta_hist.code.value_counts())\n",
    "print('Cancer clustering after:')\n",
    "print(c_meta_hist.code_latest.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sensitive to clusters before:')\n",
    "print(d_sens_hist.sensitive_k.value_counts())\n",
    "print('Sensitive to clusters after:')\n",
    "print(d_sens_hist.sensitive_k_latest.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_meta_test_tmp = c_meta_test.loc[:, ['code']]\n",
    "c_meta_test_tmp['c_name'] = c_meta_test_tmp.index.values.astype(str)\n",
    "c_meta_test_tmp = c_meta_test_tmp.rename(columns={'code':'cluster_init'})\n",
    "\n",
    "cdr_test_rslt_tmp = cdr_test_rslt[['c_name', 'cluster']]\n",
    "cdr_test_rslt_tmp = cdr_test_rslt_tmp.drop_duplicates()\n",
    "cdr_test_rslt_tmp['c_name'] = cdr_test_rslt_tmp['c_name'].astype(str)\n",
    "\n",
    "\n",
    "cdr_test_rslt_cluster = pd.merge(cdr_test_rslt_tmp, c_meta_test_tmp, on='c_name', how='left')\n",
    "\n",
    "pd.crosstab(cdr_test_rslt_cluster['cluster_init'], cdr_test_rslt_cluster['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if two_grp:\n",
    "    cdr_test_rslt_cluster = pd.merge(cdr_test_rslt_cluster, c_meta_true_tmp, on='c_name', how='left')\n",
    "    \n",
    "    print(pd.crosstab([cdr_test_rslt_cluster['cluster_true'], cdr_test_rslt_cluster['cluster_init']], cdr_test_rslt_cluster['cluster']))\n",
    "else:\n",
    "    print(pd.crosstab(cdr_test_rslt_cluster['cluster_init'], cdr_test_rslt_cluster['cluster']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    plot_c_PCA_latent(c_train, c_latent_list, c_meta_hist, n_rounds, legend_title='cluster', k=k, \n",
    "                      plot_save_path=f'{plot_folder}simu2_{num_cluster}clusters_c_latent_k{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    plot_d_PCA_latent(d_data, d_latent_list, d_sens_hist, n_rounds, legend_title='cluster', k=k, \n",
    "                      plot_save_path=f'{plot_folder}simu2_{num_cluster}clusters_d_latent_k{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    print(f'k = {k}:')\n",
    "    for b in range(n_rounds):\n",
    "        print(f'round {b}:')\n",
    "        plot_training_losses_train_test_2cols(losses_train_hist_list[b][k], best_epoch_1round = best_epos_list[b][k],\n",
    "                                              plot_save_path=f'{plot_folder}simu2_{num_cluster}clusters_losses_b{b}_k{k}.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    print(f'k = {k}:')\n",
    "    for b in range(n_rounds):\n",
    "        print(f'round {b}:')\n",
    "        plot_predict_training_losses_train_test_2cols(losses_train_hist_list[b][k], best_epoch_1round = best_epos_list[b][k])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
